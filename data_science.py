# -*- coding: utf-8 -*-
"""Data Science.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sgu2jkwVNtWG92OMgUawwvAKP5ogGaGL
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from google.colab import drive
drive.mount('/content/drive')
df = pd.read_csv('/content/drive/MyDrive/Data Science Course/healthcare-dataset-stroke-data.csv')

df.head()

print("Jumlah baris dan kolom:", df.shape)
print("\nInformasi Dataset:")
df.info()

print("\nJumlah nilai kosong:")
print(df.isnull().sum())

print("Distribusi target (stroke):")
print(df['stroke'].value_counts())
sns.countplot(x='stroke', data=df)
plt.title("Distribusi target (stroke)")
plt.show()

df=df.drop(columns=['id'])

df['bmi'] = df['bmi'].fillna(df['bmi'].median())

le = LabelEncoder()
for col in ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']:
  df[col] = le.fit_transform(df[col])

df.head()

X = df.drop(columns=['stroke'])
y = df['stroke']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
    )

print("Jumlah data latih:", X_train.shape)
print("Jumlah data uji:", X_test.shape)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model = RandomForestClassifier(
    n_estimators=100,
    random_state=42,
    class_weight='balanced'
    )

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("Akurasi:", accuracy_score(y_test, y_pred))
print("\nLaporan Klasifikasi:")
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.ylabel("Aktual")
plt.show()

import joblib

joblib.dump(model, '/content/drive/MyDrive/Data Science Course/stroke_model.pkl')
joblib.dump(scaler, '/content/drive/MyDrive/Data Science Course/stroke_scaler.pkl')

print("Model dan scaler berhasil disimpan")

df.to_csv('/content/drive/MyDrive/Data Science Course/ stroke.csv', index=False)
print("Dataset bersih telah disimpan sebagai stroke.csv")